{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "w5Zirohy46qo",
   "metadata": {
    "id": "w5Zirohy46qo"
   },
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JJFZLV_c6tsv",
   "metadata": {
    "id": "JJFZLV_c6tsv"
   },
   "source": [
    "### Problem Statement\n",
    "\n",
    "The goal is to predict whether a flight will arrive delayed by at least 15 minutes based on various features such as carrier, flight date, weekday, destination state, and flight distance.\n",
    "\n",
    "#### Candidate Models\n",
    "\n",
    "1. **Logistic Regression**\n",
    "   - **Advantages**: Simple, interpretable, and efficient for binary classification tasks.\n",
    "   - **Considerations**: Assumes linear relationship between features and log odds of the outcome.\n",
    "\n",
    "2. **Random Forest**\n",
    "   - **Advantages**: Handles non-linearity and interactions well, robust to overfitting.\n",
    "   - **Considerations**: May require tuning for optimal performance.\n",
    "\n",
    "3. **Gradient Boosting(XGBOOST)**\n",
    "   - **Advantages**: Builds trees sequentially to correct errors of previous models, generally high predictive power.\n",
    "   - **Considerations**: More computationally expensive than Random Forest, requires careful parameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xzWy6Tgnvd-N",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzWy6Tgnvd-N",
    "outputId": "f41c2644-006a-4eaf-c1e2-4f2a6a940a50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Accuracy: 0.5937, Precision: 0.5856, Recall: 0.6452, F1-score: 0.6140, ROC-AUC: 0.5936\n",
      "Random Forest: Accuracy: 0.6286, Precision: 0.6318, Recall: 0.6192, F1-score: 0.6254, ROC-AUC: 0.6286\n",
      "XGBoost: Accuracy: 0.6278, Precision: 0.6317, Recall: 0.6156, F1-score: 0.6235, ROC-AUC: 0.6278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression CV Accuracy: 0.5961 ± 0.0011\n",
      "Random Forest CV Accuracy: 0.6294 ± 0.0006\n",
      "XGBoost CV Accuracy: 0.6290 ± 0.0006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define function to evaluate the models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "# Initialize the models\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "xgb_model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Train the models\n",
    "logistic_model.fit(X_train, y_train)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the models\n",
    "logistic_metrics = evaluate_model(logistic_model, X_test, y_test)\n",
    "random_forest_metrics = evaluate_model(random_forest_model, X_test, y_test)\n",
    "xgb_metrics = evaluate_model(xgb_model, X_test, y_test)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Logistic Regression: Accuracy: {logistic_metrics[0]:.4f}, Precision: {logistic_metrics[1]:.4f}, Recall: {logistic_metrics[2]:.4f}, F1-score: {logistic_metrics[3]:.4f}, ROC-AUC: {logistic_metrics[4]:.4f}\")\n",
    "print(f\"Random Forest: Accuracy: {random_forest_metrics[0]:.4f}, Precision: {random_forest_metrics[1]:.4f}, Recall: {random_forest_metrics[2]:.4f}, F1-score: {random_forest_metrics[3]:.4f}, ROC-AUC: {random_forest_metrics[4]:.4f}\")\n",
    "print(f\"XGBoost: Accuracy: {xgb_metrics[0]:.4f}, Precision: {xgb_metrics[1]:.4f}, Recall: {xgb_metrics[2]:.4f}, F1-score: {xgb_metrics[3]:.4f}, ROC-AUC: {xgb_metrics[4]:.4f}\")\n",
    "\n",
    "# Perform cross-validation\n",
    "logistic_cv_scores = cross_val_score(logistic_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "random_forest_cv_scores = cross_val_score(random_forest_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(f\"Logistic Regression CV Accuracy: {np.mean(logistic_cv_scores):.4f} ± {np.std(logistic_cv_scores):.4f}\")\n",
    "print(f\"Random Forest CV Accuracy: {np.mean(random_forest_cv_scores):.4f} ± {np.std(random_forest_cv_scores):.4f}\")\n",
    "print(f\"XGBoost CV Accuracy: {np.mean(xgb_cv_scores):.4f} ± {np.std(xgb_cv_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vQ7L9-cq9Kl-",
   "metadata": {
    "id": "vQ7L9-cq9Kl-"
   },
   "source": [
    "Based on cross-validated accuracy, we evaluated three models for predicting flight delays:\n",
    "\n",
    "- **Logistic Regression**: Mean CV Accuracy of 0.5961 ± 0.0011\n",
    "- **Random Forest**: Mean CV Accuracy of 0.6294 ± 0.0006\n",
    "- **XGBoost**: Mean CV Accuracy of 0.6290 ± 0.0006\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "1. **Accuracy Comparison**:\n",
    "   - Random Forest and XGBoost show similar mean cross-validated accuracies (around 0.629), indicating robust performance.\n",
    "   - Logistic Regression performs lower with an accuracy around 0.596.\n",
    "\n",
    "2. **Precision and Stability**:\n",
    "   - Random Forest and XGBoost have narrower confidence intervals (\\( \\pm 0.0006 \\)) compared to Logistic Regression (\\( \\pm 0.0011 \\)), suggesting more stable performance across different folds.\n",
    "\n",
    "3. **Model Selection**:\n",
    "   - Between Random Forest and XGBoost, both perform similarly well in terms of accuracy.\n",
    "   - Choose based on additional factors such as interpretability, computational efficiency, or specific requirements of your project.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "- **Recommended Model**: Given their similar performance, either Random Forest or XGBoost would be suitable choices for predicting flight delays.\n",
    "- **Random Forest** generally shows slightly better performance across most metrics compared to XGBoost. So we will be tuning and optimizing the random forest model on the following\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
